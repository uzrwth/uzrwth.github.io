<!-- Creator     : groff version 1.23.0 -->
<!-- CreationDate: Sun Jan 18 17:28:30 2026 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title>association rules</title>
<link rel="stylesheet" href="style.css">

</head>
<body>
<a href="index.html" class="home-button">Home</a>

<h1 align="center">association rules</h1>

<a href="#frozenset: sets in .csv">frozenset: sets in .csv</a><br>
<a href="#mlxtend association_rules">mlxtend association_rules</a><br>

<hr>


<h2>frozenset: sets in .csv
<a name="frozenset: sets in .csv"></a>
</h2>


<p style="margin-top: 1em">Before writing code, we must
decide how to represent sets in a .csv file.</p>

<p style="margin-top: 1em"><pre><code>support,itemsets
0.11872533300444006,frozenset({13176})
0.05557782437099161,frozenset({47209})
0.002081277750370005,&quot;frozenset({46979, 48679})&quot;</code></pre></p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; import pandas
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.read_csv(&quot;frequent_itemsets.csv&quot;)
&gt;&gt;&gt; df.dtypes
support     float64
itemsets     object
dtype: object
&gt;&gt;&gt; df2 = pd.read_csv(&quot;groceries_basket.csv&quot;)
&gt;&gt;&gt; df2.dtypes
order_id                       int64
product_id                     int64
product_name                  object
category                      object
add_to_cart_sequence_index     int64
dtype: object
&gt;&gt;&gt;


&gt;&gt;&gt; df2[&#x27;product_name&#x27;].values
array([&#x27;Bulgarian Yogurt&#x27;, &#x27;Organic Celery Hearts&#x27;,
       &#x27;Lightly Smoked Sardines in Olive Oil&#x27;, ...,
       &#x27;Organic Unsweetened Almond Milk&#x27;, &#x27;Creamy Peanut Butter&#x27;,
       &#x27;Broccoli Florettes&#x27;], shape=(573124,), dtype=object)
&gt;&gt;&gt; type(df2[&#x27;product_name&#x27;].values)
&lt;class &#x27;numpy.ndarray&#x27;&gt;

&gt;&gt;&gt; type(df2[&#x27;product_name&#x27;].values[0])
&lt;class &#x27;str&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">pandas&rsquo; read_csv() parses
data into basic types: int64, float64, object.</p>

<p style="margin-top: 1em">Although shown as
&rsquo;object&rsquo; by dtypes, its real data type is
&lt;class &rsquo;str&rsquo;&gt;.</p>

<p style="margin-top: 1em">When reduced to one dimension,
df becomes a series. <pre><code>&gt;&gt;&gt; type(df2[&#x27;product_name&#x27;])
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">To construct a .csv file with
strings that have &quot;,&quot; within it, we need to quote
the string. After that, the parsing has no difference from a
normal .csv file.</p>

<p style="margin-top: 1em">To retrieve the original set
object from the &lt;class &rsquo;str&rsquo;&gt;, there is
the frozenset library.</p>

<p style="margin-top: 1em">The ast module helps processing
trees of the Python abstract syntax grammar. In fact, in the
.csv file, the set is stored as a line of Python code. With
literal_eval, we reconstruct the frozenset object from the
literal.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; import ast
&gt;&gt;&gt; def safe_convert_frozenset(s):
...     if s.startswith(&quot;frozenset(&quot;) and s.endswith(&quot;)&quot;):
...         inner = s[10:-1]
...         try:
...             inner_value = ast.literal_eval(inner)
...             return frozenset(inner_value)
...         except ValueError:
...             pass
...     raise ValueError(&quot;Invalid frozenset format&quot;)
...
... freq_df = df.copy()
... freq_df[&#x27;itemsets&#x27;] = freq_df[&#x27;itemsets&#x27;].apply(safe_convert_frozenset)
...
&gt;&gt;&gt; freq_df.dtypes
support     float64
itemsets     object
dtype: object</code></pre></p>

<p style="margin-top: 1em">Why do we need frozenset? Why
not just using the simple set?</p>

<p style="margin-top: 1em">frozenset is immutable and
hashable. Therefore, if we want it to be used as the key in
a dict, then we should use frozenset rather than the simple
set.</p>

<p style="margin-top: 1em">For an object to be hashable, it
must be immutable. A string can be used as a key because it
is immutable. Any operation on a string always creates a new
string object.</p>

<p style="margin-top: 1em"><b>something deep in
Python</b></p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; a = frozenset({1})
&gt;&gt;&gt; b = frozenset({1})
&gt;&gt;&gt; id(a)
140178894736064
&gt;&gt;&gt; id(b)
140178894736288
&gt;&gt;&gt; c[a] = 9
&gt;&gt;&gt; c[b]
9
&gt;&gt;&gt;

&gt;&gt;&gt; a.__hash__()
-558064481276695278
&gt;&gt;&gt; b.__hash__()
-558064481276695278
&gt;&gt;&gt;

&gt;&gt;&gt; e=&quot;a&quot;
&gt;&gt;&gt; e.__hash__()
-3006155391340656490
&gt;&gt;&gt; &quot;a&quot;.__hash__()
-3006155391340656490


&gt;&gt;&gt; a = 5
&gt;&gt;&gt; a.__hash__()
5
&gt;&gt;&gt; a=1.23
&gt;&gt;&gt; a.__hash__()
530343892119149569

&gt;&gt;&gt; type(a)
&lt;class &#x27;float&#x27;&gt;
&gt;&gt;&gt; type(5)
&lt;class &#x27;int&#x27;&gt;

&gt;&gt;&gt; c[{}] = 9
Traceback (most recent call last):
  File &quot;&lt;python-input-58&gt;&quot;, line 1, in &lt;module&gt;
    c[{}] = 9
    ~^^^^
TypeError: unhashable type: &#x27;dict&#x27;

&gt;&gt;&gt; t={}
&gt;&gt;&gt; t.__hash__()
Traceback (most recent call last):
  File &quot;&lt;python-input-60&gt;&quot;, line 1, in &lt;module&gt;
    t.__hash__()
    ~~~~~~~~~~^^
TypeError: &#x27;NoneType&#x27; object is not callable
&gt;&gt;&gt; t.__hash__
&gt;&gt;&gt; type(t.__hash__)
&lt;class &#x27;NoneType&#x27;&gt;


&gt;&gt;&gt; type(None)
&lt;class &#x27;NoneType&#x27;&gt;
&gt;&gt;&gt; id(None)
94040144899728

&gt;&gt;&gt; a = None
&gt;&gt;&gt; b = None
&gt;&gt;&gt; id(a)
94040144899728
&gt;&gt;&gt; id(b)
94040144899728
&gt;&gt;&gt; a = 3
&gt;&gt;&gt; b = 3
&gt;&gt;&gt; id(a)
94040145005360
&gt;&gt;&gt; id(b)
94040145005360


# COW

&gt;&gt;&gt; b = 4
&gt;&gt;&gt; id(b)
94040145005392</code></pre></p>

<p style="margin-top: 1em">Everything in Python is an
object.</p>

<p style="margin-top: 1em">We&rsquo;re getting off track,
let&rsquo;s return to the main point.</p>

<h2>mlxtend association_rules
<a name="mlxtend association_rules"></a>
</h2>


<p style="margin-top: 1em">checking for the source
file:</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; import mlxtend
&gt;&gt;&gt; mlxtend.__file__
&#x27;/home/l/micromamba/envs/py313/lib/python3.13/site-packages/mlxtend/__init__.py&#x27;</code></pre></p>

<p style="margin-top: 1em"><b>some basic Python
concepts</b></p>

<p style="margin-top: 1em">There is an __init__.py in the
directory, so mlxtend is a package.</p>

<p style="margin-top: 1em">Every .py file is a module.</p>

<p style="margin-top: 1em">import mlxtend: importing the
package.</p>

<p style="margin-top: 1em">from mlxtend.frequent_patterns
import apriori, association_rules: importing functions
apriori and association_rules.</p>

<p style="margin-top: 1em">functions are also objects, of
type &lt;class &rsquo;function&rsquo;&gt;.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; type(association_rules)
&lt;class &#x27;function&#x27;&gt;
&gt;&gt;&gt; def a():
...     return 1
...
&gt;&gt;&gt; type(a)
&lt;class &#x27;function&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">import foo: first check if the
name is a directory, if yes, look for __init__.py, if found,
then this is a package. if not, look for foo.py. if found,
it is a module. then load it. loading a module: if the
module object already exists, then returns. Otherwise,
executes the code in foo.py from top to bottom, creates a
module object and returns it.</p>

<p style="margin-top: 1em">What do we need to put in
__init__.py when we want to create a package?</p>

<p style="margin-top: 1em">__init__.py can be empty if we
just want a package.</p>

<p style="margin-top: 1em">In __init__.py we can expose
some modules. We can use __all__ to control what we want to
expose. Without __all__, everything will be exposed.</p>

<p style="margin-top: 1em"><pre><code>from .module1 import foo
from .module2 import bar</code></pre></p>

<p style="margin-top: 1em"><pre><code>from mlxtend.frequent_patterns import apriori, association_rules

def safe_convert_frozenset(s):
    if s.startswith(&quot;frozenset(&quot;) and s.endswith(&quot;)&quot;):
        inner = s[10:-1]
        try:
            inner_value = ast.literal_eval(inner)
            return frozenset(inner_value)
        except ValueError:
            pass
    raise ValueError(&quot;Invalid frozenset format&quot;)

freq_df = df.copy()
freq_df[&#x27;itemsets&#x27;] = freq_df[&#x27;itemsets&#x27;].apply(safe_convert_frozenset)

rules = association_rules(freq_df, metric=&quot;confidence&quot;, min_threshold=0.2, num_itemsets=orders_num).round(2)
lifts = rules[&#x27;lift&#x27;]
display(f&quot;Lift&#x27;s mean: {lifts.mean().round(2)}. Lift&#x27;s median: {lifts.median().round(2)}.&quot;)</code></pre></p>

<p style="margin-top: 1em">association_rules requires df to
have mandatory columns:</p>

<p style="margin-top: 1em"><pre><code># check for mandatory columns
    if not all(col in df.columns for col in [&quot;support&quot;, &quot;itemsets&quot;]):
        raise ValueError(
            &quot;Dataframe needs to contain the\
                         columns &#x27;support&#x27; and &#x27;itemsets&#x27;&quot;
        )</code></pre></p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; df.columns
Index([&#x27;order_id&#x27;, &#x27;product_id&#x27;, &#x27;product_name&#x27;, &#x27;category&#x27;,
       &#x27;add_to_cart_sequence_index&#x27;],
      dtype=&#x27;object&#x27;)
&gt;&gt;&gt; &#x27;order_id&#x27; in df.columns
True
&gt;&gt;&gt; type(df.columns)
&lt;class &#x27;pandas.core.indexes.base.Index&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">How does &rsquo;in&rsquo; work
in Python?</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; df.columns.__contains__
&lt;bound method Index.__contains__ of Index([&#x27;order_id&#x27;, &#x27;product_id&#x27;, &#x27;product_name&#x27;, &#x27;category&#x27;,
       &#x27;add_to_cart_sequence_index&#x27;],
      dtype=&#x27;object&#x27;)&gt;
&gt;&gt;&gt; a=[]
&gt;&gt;&gt; type(a.__contains__)
&lt;class &#x27;method-wrapper&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">If I implement a class with the
function __contains__, then such a class works with the
&rsquo;in&rsquo; keyword.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; class MyContainer:
...     def __contains__(self, item):
...         return item % 2 == 0  # only even numbers are &quot;in&quot; this container
...
... c = MyContainer()
...
... print(2 in c)  # True
... print(3 in c)  # False
...
True
False</code></pre></p>

<p style="margin-top: 1em">Kulczynski similarity
coefficient: it&rsquo;s a measure of similarity between sets
or vectors.</p>

<p style="margin-top: 1em"><pre><code>def kulczynski_helper(sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_):
        conf_AC = sAC * (num_itemsets - disAC) / (sA * (num_itemsets - disA) - dis_int)
        conf_CA = sAC * (num_itemsets - disAC) / (sC * (num_itemsets - disC) - dis_int_)
        kulczynski = (conf_AC + conf_CA) / 2
        return kulczynski


 # metrics for association rules
    metric_dict = {
        &quot;antecedent support&quot;: lambda _, sA, ___, ____, _____, ______, _______, ________: sA,
        &quot;consequent support&quot;: lambda _, __, sC, ____, _____, ______, _______, ________: sC,
        &quot;support&quot;: lambda sAC, _, __, ___, ____, _____, ______, _______: sAC,
        &quot;confidence&quot;: lambda sAC, sA, _, disAC, disA, __, dis_int, ___: (
            sAC * (num_itemsets - disAC)
        )
        / (sA * (num_itemsets - disA) - dis_int),
        &quot;lift&quot;: lambda sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_: metric_dict[
            &quot;confidence&quot;
        ](sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_)
        / sC,
        &quot;representativity&quot;: lambda _, __, ___, disAC, ____, ______, _______, ________: (
            num_itemsets - disAC
        )
        / num_itemsets,
        &quot;leverage&quot;: lambda sAC, sA, sC, _, __, ____, _____, ______: metric_dict[
            &quot;support&quot;
        ](sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_)
        - sA * sC,
        &quot;conviction&quot;: lambda sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_: conviction_helper(
            metric_dict[&quot;confidence&quot;](
                sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
            ),
            sC,
        ),
        &quot;zhangs_metric&quot;: lambda sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_: zhangs_metric_helper(
            sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
        ),
        &quot;jaccard&quot;: lambda sAC, sA, sC, _, __, ____, _____, ______: jaccard_metric_helper(
            sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
        ),
        &quot;certainty&quot;: lambda sAC, sA, sC, _, __, ____, _____, ______: certainty_metric_helper(
            sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
        ),
        &quot;kulczynski&quot;: lambda sAC, sA, sC, _, __, ____, _____, ______: kulczynski_helper(
            sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
        ),
    }</code></pre></p>

<p style="margin-top: 1em">What is the zip object?</p>

<p style="margin-top: 1em"><pre><code>zip(*iterables, strict=False)

&gt;&gt;&gt; a = range(3)
&gt;&gt;&gt; type(a)
&lt;class &#x27;range&#x27;&gt;
&gt;&gt;&gt; a.__iter__()
&lt;range_iterator object at 0x7f8f317819b0&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; b=&#x27;abcd&#x27;
&gt;&gt;&gt; b.__iter__()
&lt;str_ascii_iterator object at 0x7f8f327acaf0&gt;
&gt;
&gt;&gt;&gt; bi = b.__iter__()
&gt;&gt;&gt; type(bi)
&lt;class &#x27;str_ascii_iterator&#x27;&gt;
&gt;&gt;&gt; ai=a.__iter__()
&gt;&gt;&gt; type(ai)
&lt;class &#x27;range_iterator&#x27;&gt;

&gt;&gt;&gt; list(zip(&#x27;abcdefg&#x27;, range(3), range(4)))
[(&#x27;a&#x27;, 0, 0), (&#x27;b&#x27;, 1, 1), (&#x27;c&#x27;, 2, 2)]
&gt;&gt;&gt; type(t)
&lt;class &#x27;zip&#x27;&gt;
&gt;&gt;&gt; t.__iter__()
&lt;zip object at 0x7f8f31136000&gt;
&gt;&gt;&gt; type(t.__iter__())
&lt;class &#x27;zip&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">*iterables: * unlimited input
parameters.</p>

<p style="margin-top: 1em"><pre><code># get dict of {frequent itemset} -&gt; support
    keys = df[&quot;itemsets&quot;].values
    values = df[&quot;support&quot;].values
    frozenset_vect = np.vectorize(lambda x: frozenset(x))
    frequent_items_dict = dict(zip(frozenset_vect(keys), values))</code></pre></p>

<p style="margin-top: 1em">zip: create a zip object, each
element is a tuple of key-value.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; d = dict([(&#x27;a&#x27;, 2), (&#x27;b&#x27;, 3)])
&gt;&gt;&gt; d
{&#x27;a&#x27;: 2, &#x27;b&#x27;: 3}

&gt;&gt;&gt; type(df[&quot;order_id&quot;].values)
&lt;class &#x27;numpy.ndarray&#x27;&gt;
&gt;&gt;&gt; type(df[&quot;order_id&quot;].values[0])
&lt;class &#x27;numpy.int64&#x27;&gt;

Help on class zip in module builtins:
Help on class int64 in module numpy:

import numpy
import builtins

help(numpy)
Help on package numpy:

NAME
    numpy

DESCRIPTION
    NumPy
    =====

    Provides
      1. An array object of arbitrary homogeneous items
      2. Fast mathematical operations over arrays
      3. Linear Algebra, Fourier Transforms, Random Number Generation

    How to use the documentation
    ----------------------------

help(builtins)
Help on built-in module builtins:

NAME
    builtins - Built-in functions, types, exceptions, and other objects.

DESCRIPTION
    This module provides direct access to all &#x27;built-in&#x27;
    identifiers of Python; for example, builtins.len is
    the full name for the built-in function len().

    This module is not normally accessed explicitly by most
    applications, but can be useful in modules that provide
    objects with the same name as a built-in value, but in
    which the built-in of that name is also needed.

&gt;&gt;&gt; builtins.__file__
Traceback (most recent call last):
  File &quot;&lt;python-input-59&gt;&quot;, line 1, in &lt;module&gt;
    builtins.__file__
AttributeError: module &#x27;builtins&#x27; has no attribute &#x27;__file__&#x27;. Did you mean: &#x27;__name__&#x27;?
&gt;&gt;&gt; numpy.__file__
&#x27;/home/l/micromamba/envs/py313/lib/python3.13/site-packages/numpy/__init__.py&#x27;</code></pre></p>

<p style="margin-top: 1em">The builtins module is
implemented in Python/bltinmodule.c (cpython).</p>

<p style="margin-top: 1em">builtins is a module, but numpy
is a package.</p>

<p style="margin-top: 1em"><pre><code>PyTypeObject PyFilter_Type = {
PyTypeObject PyMap_Type = {
PyTypeObject PyZip_Type = {

    SETBUILTIN(&quot;None&quot;,                  Py_None);
    SETBUILTIN(&quot;Ellipsis&quot;,              Py_Ellipsis);
    SETBUILTIN(&quot;NotImplemented&quot;,        Py_NotImplemented);
    SETBUILTIN(&quot;False&quot;,                 Py_False);
    SETBUILTIN(&quot;True&quot;,                  Py_True);
    SETBUILTIN(&quot;bool&quot;,                  &amp;PyBool_Type);
    SETBUILTIN(&quot;memoryview&quot;,        &amp;PyMemoryView_Type);
    SETBUILTIN(&quot;bytearray&quot;,             &amp;PyByteArray_Type);
    SETBUILTIN(&quot;bytes&quot;,                 &amp;PyBytes_Type);
    SETBUILTIN(&quot;classmethod&quot;,           &amp;PyClassMethod_Type);
    SETBUILTIN(&quot;complex&quot;,               &amp;PyComplex_Type);
    SETBUILTIN(&quot;dict&quot;,                  &amp;PyDict_Type);
    SETBUILTIN(&quot;enumerate&quot;,             &amp;PyEnum_Type);
    SETBUILTIN(&quot;filter&quot;,                &amp;PyFilter_Type);
    SETBUILTIN(&quot;float&quot;,                 &amp;PyFloat_Type);
    SETBUILTIN(&quot;frozenset&quot;,             &amp;PyFrozenSet_Type);

    SETBUILTIN(&quot;dict&quot;,                  &amp;PyDict_Type);</code></pre></p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; type(numpy)
&lt;class &#x27;module&#x27;&gt;
&gt;&gt;&gt; type(numpy.int64)
&lt;class &#x27;type&#x27;&gt;
&gt;&gt;&gt; type(builtins)
&lt;class &#x27;module&#x27;&gt;</code></pre></p>

<p style="margin-top: 1em">Both packages and modules are
represented as &lt;class &rsquo;module&rsquo;&gt; in
Python&rsquo;s runtime.</p>

<p style="margin-top: 1em">packages and modules are mostly
the same. A package in its nature is no more than modules
living in a namespace specified by __init__.py.</p>

<p style="margin-top: 1em">Now that association_rules has
built the frequent_items_dict. It&rsquo;s time to collect
frequent rules.</p>

<p style="margin-top: 1em"><pre><code># prepare buckets to collect frequent rules
    rule_antecedents = []
    rule_consequents = []
    rule_supports = []</code></pre></p>

<p style="margin-top: 1em"><pre><code>null_values : bool (default: False)
      In case there are null values as NaNs in the original input data


    # if null values exist, df_orig must be provided
    if null_values and df_orig is None:
        raise TypeError(&quot;If null values exist, df_orig must be provided.&quot;)
    # if null values exist, num_itemsets must be provided
    if null_values and num_itemsets == 1:
        raise TypeError(&quot;If null values exist, num_itemsets must be provided.&quot;)


    for k in frequent_items_dict.keys():
        sAC = frequent_items_dict[k]
        # to find all possible combinations</code></pre></p>

<p style="margin-top: 1em">Iteration through a dict with
.keys() is not as efficient as with .items(). Because with
.keys(), it needs one more indexing step to fetch the
value.</p>

<p style="margin-top: 1em"><pre><code># to find all possible combinations
        for idx in range(len(k) - 1, 0, -1):
            # of antecedent and consequent

&gt;&gt;&gt; for i in range(5, 0, -1):
...     print(i)
...
5
4
3
2
1
&gt;&gt;&gt; for i in range(0, 5):
...     print(i)
...
0
1
2
3
4

&gt;&gt;&gt; a=frozenset({1,2})
&gt;&gt;&gt; b=frozenset({2,1})
&gt;&gt;&gt; a
frozenset({1, 2})
&gt;&gt;&gt; b
frozenset({1, 2})
&gt;&gt;&gt; a==b
True

&gt;&gt;&gt; for i in range(0, 0, -1):
...     print(i)
...
&gt;&gt;&gt;

# loops: 0</code></pre></p>

<p style="margin-top: 1em"><pre><code>from itertools import combinations

            # of antecedent and consequent
            for c in combinations(k, r=idx):
                antecedent = frozenset(c)
                consequent = k.difference(antecedent)

class combinations(builtins.object)
 |  combinations(iterable, r)
 |
 |  Return successive r-length combinations of elements in the iterable.
 |
 |  combinations(range(4), 3) --&gt; (0,1,2), (0,1,3), (0,2,3), (1,2,3)</code></pre></p>

<p style="margin-top: 1em">The support_only parameter:</p>

<p style="margin-top: 1em"><pre><code>try:
                        sA = frequent_items_dict[antecedent]
                        sC = frequent_items_dict[consequent]


                    except KeyError as e:
                        s = (
                            str(e) + &quot;You are likely getting this error&quot;
                            &quot; because the DataFrame is missing &quot;
                            &quot; antecedent and/or consequent &quot;
                            &quot; information.&quot;
                            &quot; You can try using the &quot;
                            &quot; `support_only=True` option&quot;
                        )
                        raise KeyError(s)

    support_only : bool (default: False)
      Only computes the rule support and fills the other
      metric columns with NaNs. This is useful if:

      a) the input DataFrame is incomplete, e.g., does
      not contain support values for all rule antecedents
      and consequents

      b) you simply want to speed up the computation because
      you don&#x27;t need the other metrics.</code></pre></p>

<p style="margin-top: 1em">If a set is a frequent itemset,
then all of its subsets are also frequent itemsets. This
means we won&rsquo;t need to use the support_only in most
cases.</p>

<p style="margin-top: 1em">How does it handle with
null_values? <pre><code># if null values exist, df_orig must be provided
    if null_values and df_orig is None:
        raise TypeError(&quot;If null values exist, df_orig must be provided.&quot;)

    # check for valid input
    fpc.valid_input_check(df_orig, null_values)</code></pre></p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; df.shape
(1977, 2)
&gt;&gt;&gt; df.shape[0]
1977
&gt;&gt;&gt; len(df)
1977

&gt;&gt;&gt; hasattr(df, &quot;sparse&quot;)
False
&gt;&gt;&gt; hasattr(df, &quot;dtypes&quot;)
True
&gt;&gt;&gt; hasattr(df, &quot;groupby&quot;)
True

Help on built-in function hasattr in module builtins:

hasattr(obj, name, /)
    Return whether the object has an attribute with the given name.

    This is done by calling getattr(obj, name) and catching AttributeError.</code></pre></p>

<p style="margin-top: 1em">df.dtypes is a series.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; df.dtypes
support     float64
itemsets     object
dtype: object
&gt;&gt;&gt; type(df.dtypes)
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;


    if f&quot;{type(df)}&quot; == &quot;&lt;class &#x27;pandas.core.frame.SparseDataFrame&#x27;&gt;&quot;:
        msg = (
            &quot;SparseDataFrame support has been deprecated in pandas 1.0,&quot;
            &quot; and is no longer supported in mlxtend. &quot;
            &quot; Please&quot;
            &quot; see the pandas migration guide at&quot;
            &quot; https://pandas.pydata.org/pandas-docs/&quot;
            &quot;stable/user_guide/sparse.html#sparse-data-structures&quot;
            &quot; for supporting sparse data in DataFrames.&quot;
        )
        raise TypeError(msg)

    # Fast path: if all columns are boolean, there is nothing to checks
    if null_values:
        all_bools = (
            df.apply(lambda col: col.apply(lambda x: pd.isna(x) or isinstance(x, bool)))
            .all()
            .all()
        )
    else:
        all_bools = df.dtypes.apply(pd.api.types.is_bool_dtype).all()
    if not all_bools:
        ...


Help on function is_bool_dtype in module pandas.core.dtypes.common:

is_bool_dtype(arr_or_dtype) -&gt; &#x27;bool&#x27;
    Check whether the provided array or dtype is of a boolean dtype.

&gt;&gt;&gt; df[&quot;a&quot;]=False
&gt;&gt;&gt; pd.api.types.is_bool_dtype(df[&quot;a&quot;])
True
&gt;&gt;&gt; pd.api.types.is_bool_dtype([True])
False

&gt;&gt;&gt; isinstance(1, int)
True


&gt;&gt;&gt; df.apply(lambda x: print(type(x)))
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;
support     None
itemsets    None
a           None
dtype: object
&gt;&gt;&gt; df
       support                      itemsets      a
0     0.118725            frozenset({13176})  False
1     0.055578            frozenset({47209})  False
2     0.015432            frozenset({22035})  False
3     0.008048            frozenset({10246})  False
4     0.029462            frozenset({46979})  False
...        ...                           ...    ...
1972  0.003176     frozenset({46906, 24852})  False
1973  0.001542     frozenset({46906, 21903})  False
1974  0.001634     frozenset({18523, 24852})  False
1975  0.001788     frozenset({33754, 33787})  False
1976  0.001788  frozenset({33754, 99933787})  False

[1977 rows x 3 columns]

Help on method apply in module pandas.core.frame:

apply(
    func: &#x27;AggFuncType&#x27;,
    axis: &#x27;Axis&#x27; = 0,
    raw: &#x27;bool&#x27; = False,
    result_type: &quot;Literal[&#x27;expand&#x27;, &#x27;reduce&#x27;, &#x27;broadcast&#x27;] | None&quot; = None,
    args=(),
    by_row: &quot;Literal[False, &#x27;compat&#x27;]&quot; = &#x27;compat&#x27;,
    engine: &quot;Literal[&#x27;python&#x27;, &#x27;numba&#x27;]&quot; = &#x27;python&#x27;,
    engine_kwargs: &#x27;dict[str, bool] | None&#x27; = None,
    **kwargs
) method of pandas.core.frame.DataFrame instance
    Apply a function along an axis of the DataFrame.

    Objects passed to the function are Series objects whose index is
    either the DataFrame&#x27;s index (``axis=0``) or the DataFrame&#x27;s columns
    (``axis=1``). By default (``result_type=None``), the final return type
    is inferred from the return type of the applied function. Otherwise,
    it depends on the `result_type` argument.

df.apply(func, axis=0) # default axis=0</code></pre></p>

<p style="margin-top: 1em">axis=0: move in the direction of
rows, that is, to apply on a column</p>

<p style="margin-top: 1em">axis=1: move in the direction of
columns, that is, to apply on a row</p>

<p style="margin-top: 1em">The default axis is 0,
therefore, df.apply applies the function on columns.</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; df.apply(lambda x: print(1))
1
1
1
support     None
itemsets    None
a           None
dtype: object

&gt;&gt;&gt; b=df.apply(lambda x: print(1))
1
1
1
&gt;&gt;&gt; b
support     None
itemsets    None
a           None
dtype: object

&gt;&gt;&gt; type(b)
&lt;class &#x27;pandas.core.series.Series&#x27;&gt;

&gt;&gt;&gt; b=df.apply(lambda x: 1)
&gt;&gt;&gt; b
support     1
itemsets    1
a           1
dtype: int64
&gt;&gt;&gt; b.dtype
dtype(&#x27;int64&#x27;)

&gt;&gt;&gt; df.apply(lambda x: type(x.dtype))
support     &lt;class &#x27;numpy.dtypes.Float64DType&#x27;&gt;
itemsets     &lt;class &#x27;numpy.dtypes.ObjectDType&#x27;&gt;
a              &lt;class &#x27;numpy.dtypes.BoolDType&#x27;&gt;
dtype: object</code></pre></p>

<p style="margin-top: 1em">This line iterates through
columns of df, and for each column (type Series) iterates
through each value, and for each value checks isna or
isinstance.</p>

<p style="margin-top: 1em">The shape of the resulting df is
the same as the original, but values are transformed into
bools.</p>

<p style="margin-top: 1em"><pre><code>df.apply(lambda col: col.apply(lambda x: pd.isna(x) or isinstance(x, bool)))

&gt;&gt;&gt; b = df.apply(lambda col: col.apply(lambda x: pd.isna(x) or isinstance(x, bool)))
&gt;&gt;&gt; type(b)
&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;
&gt;&gt;&gt; b
      support  itemsets     a
0       False     False  True
1       False     False  True
2       False     False  True
3       False     False  True
4       False     False  True
...       ...       ...   ...
1972    False     False  True
1973    False     False  True
1974    False     False  True
1975    False     False  True
1976    False     False  True

[1977 rows x 3 columns]


Help on method all in module pandas.core.frame:

all(
    axis: &#x27;Axis | None&#x27; = 0,
    bool_only: &#x27;bool&#x27; = False,
    skipna: &#x27;bool&#x27; = True,
    **kwargs
) -&gt; &#x27;Series | bool&#x27; method of pandas.core.frame.DataFrame instance
    Return whether all elements are True, potentially over an axis.</code></pre></p>

<p style="margin-top: 1em">Without specifying axis, all()
iterates through all columns (in the direction of rows),
treated each column as an array and checks if all values are
True.</p>

<p style="margin-top: 1em">The result is a Series with
column names as indices.</p>

<p style="margin-top: 1em"><pre><code>df.apply(lambda col: col.apply(lambda x: pd.isna(x) or isinstance(x, bool)))
            .all()
            .all()

&gt;&gt;&gt; df.all().all()
np.False_
&gt;&gt;&gt; t=df.all().all()
&gt;&gt;&gt; t.__bool__()
False
&gt;&gt;&gt; False.__bool__()
False</code></pre></p>

<p style="margin-top: 1em">By applying all() for 2 times,
this line checks whether all values in the 2-dimensional
matrix are all True values.</p>

<p style="margin-top: 1em">Applying all() on a Series
reduces a Series to a single value.</p>

<p style="margin-top: 1em">valid_input_check returns
nothing. It raises an exception only if it finds the data
invalid. Whether the data is all True or nothing, it
won&rsquo;t matter.</p>

<p style="margin-top: 1em">In association_rules(), it
checks for df_orig, which defaults to None, hence this check
never fails for our case.</p>

<p style="margin-top: 1em"><pre><code># check for valid input
    fpc.valid_input_check(df_orig, null_values)</code></pre></p>

<p style="margin-top: 1em">Supports of antecedent and
consequent.</p>

<p style="margin-top: 1em"><pre><code>sA = frequent_items_dict[antecedent]
                        sC = frequent_items_dict[consequent]

                        # if the input dataframe is complete
                        if not null_values:
                            disAC, disA, disC, dis_int, dis_int_ = 0, 0, 0, 0, 0

                        else:
                            an = list(antecedent)</code></pre></p>

<p style="margin-top: 1em">A large part of the code handles
the case with null_values = True. In our case, we passed in
df and used the default null_values = False.</p>

<p style="margin-top: 1em">Hence, we jump directly to the
core logic.</p>

<p style="margin-top: 1em"><pre><code>score = metric_dict[metric](
                    sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
                )
                if score &gt;= min_threshold:
                    rule_antecedents.append(antecedent)
                    rule_consequents.append(consequent)
                    rule_supports.append(
                        [sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_]
                    )</code></pre></p>

<p style="margin-top: 1em">We keep the rule if we found it
larger than the min_threshold.</p>

<p style="margin-top: 1em">These dis* values are all zeros
because our input dataframe is complete.</p>

<p style="margin-top: 1em">The computation for the
confidence metric is simple:</p>

<p style="margin-top: 1em"><pre><code>&quot;confidence&quot;: lambda sAC, sA, _, disAC, disA, __, dis_int, ___: (
            sAC * (num_itemsets - disAC)
        )
        / (sA * (num_itemsets - disA) - dis_int),</code></pre></p>

<p style="margin-top: 1em">The dis* prefix means disabled.
In our case, our df is complete, so there are no disabled
itemsets.</p>

<p style="margin-top: 1em">In our case, since df is a
complete dataframe, the value of num_itemsets is canceled
out.</p>

<p style="margin-top: 1em">Basically,
&quot;confidence&quot; computes the probability of: if A
happens, then what is the probability of C happens.
P(C|A).</p>

<p style="margin-top: 1em">Association rules are computed
only from frequent itemsets with at least two items.</p>

<p style="margin-top: 1em">In Python, if we loaded a
module, and then we modified it in the source code and
import again, the module doesn&rsquo;t get changed. Because
the runtime thinks the module has been loaded already, the
duplicated import statement will be ignored.</p>

<p style="margin-top: 1em">To force a reload, use this:</p>

<p style="margin-top: 1em"><pre><code>importlib.reload(mymodule)</code></pre></p>

<p style="margin-top: 1em">To check an empty list:</p>

<p style="margin-top: 1em"><pre><code>&gt;&gt;&gt; a=[]
&gt;&gt;&gt; if a:
...     print(1)
...
&gt;&gt;&gt; a=[1]
&gt;&gt;&gt; if a:
...     print(1)
...
1



    # check if frequent rule was generated
    if not rule_supports:
        return pd.DataFrame(columns=[&quot;antecedents&quot;, &quot;consequents&quot;] + return_metrics)

    else:
        # generate metrics
        rule_supports = np.array(rule_supports).T.astype(float)

_metrics = [
    &quot;antecedent support&quot;,
    &quot;consequent support&quot;,
    &quot;support&quot;,
    &quot;confidence&quot;,
    &quot;lift&quot;,
    &quot;representativity&quot;,
    &quot;leverage&quot;,
    &quot;conviction&quot;,
    &quot;zhangs_metric&quot;,
    &quot;jaccard&quot;,
    &quot;certainty&quot;,
    &quot;kulczynski&quot;,
]</code></pre></p>

<p style="margin-top: 1em">Construct the output:</p>

<p style="margin-top: 1em"><pre><code># generate metrics
        rule_supports = np.array(rule_supports).T.astype(float)
        df_res = pd.DataFrame(
            data=list(zip(rule_antecedents, rule_consequents)),
            columns=[&quot;antecedents&quot;, &quot;consequents&quot;],
        )

        if support_only:
            sAC = rule_supports[0]
            for m in return_metrics:
                df_res[m] = np.nan
            df_res[&quot;support&quot;] = sAC

        else:
            sAC = rule_supports[0]
            sA = rule_supports[1]
            sC = rule_supports[2]
            disAC = rule_supports[3]
            disA = rule_supports[4]
            disC = rule_supports[5]
            dis_int = rule_supports[6]
            dis_int_ = rule_supports[7]

            for m in return_metrics:
                df_res[m] = metric_dict[m](
                    sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
                )

        return df_res


&gt;&gt;&gt; rule_supports=[[1,2,3],[4,5,6]]
&gt;&gt;&gt; rule_supports = np.array(rule_supports).T.astype(float)
&gt;&gt;&gt; type(rule_supports)
&lt;class &#x27;numpy.ndarray&#x27;&gt;
&gt;&gt;&gt; rule_supports
array([[1., 4.],
       [2., 5.],
       [3., 6.]])
&gt;&gt;&gt; rule_supports[0]
array([1., 4.])
&gt;&gt;&gt; rule_supports[0][1]
np.float64(4.0)</code></pre></p>

<p style="margin-top: 1em">np.array transforms an array
into a matrix. This makes adding columns to df easy.</p>

<p style="margin-top: 1em">Here it only checks the score
for the specific metric and makes sure it is above
threshold. For the result output, it computes all available
metrics.</p>

<p style="margin-top: 1em">That is also why we have lifts
in the returning result.</p>

<p style="margin-top: 1em"><pre><code>score = metric_dict[metric](
                    sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
                )
                if score &gt;= min_threshold:
                    rule_antecedents.append(antecedent)
                    rule_consequents.append(consequent)
                    rule_supports.append(
                        [sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_]
                    )

            for m in return_metrics:
                df_res[m] = metric_dict[m](
                    sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_
                )

        &quot;lift&quot;: lambda sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_: metric_dict[
            &quot;confidence&quot;
        ](sAC, sA, sC, disAC, disA, disC, dis_int, dis_int_)
        / sC,</code></pre></p>

<p style="margin-top: 1em">Lift is computed as confidence
divided by the consequent. (P(AC) / P(A) / P(C))</p>
 
<p style="margin-top: 1em"><img src="lift.png" style="display:block; margin:auto;"></p>
<hr>
</body>
</html>
